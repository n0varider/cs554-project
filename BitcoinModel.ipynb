{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125b7c4-09af-416f-aee9-f5cf761b1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from prophetmodel import ProphetModel\n",
    "from lstmmodel import LSTMModel\n",
    "from seriesdata import SeriesDataset\n",
    "from residualnn import ResidualNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775aac3-f9af-46d0-89be-6767628eea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ca544-29ba-43b3-a491-9f46e2150f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "def trainm(model, loader, optimizer, scheduler, loss_fn, epochs):\n",
    "\n",
    "    model.train()\n",
    "    samples = len(loader.dataset)\n",
    "    epoch = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        total_loss = 0.0\n",
    "        progress = tqdm(loader, desc=f'Epoch {epoch+1}/{epochs}', leave=True)\n",
    "        \n",
    "        for i, (x, y) in enumerate(progress):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(x).squeeze(1)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / samples\n",
    "            \n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"NaN loss encountered in epoch {epoch+1}, batch. Stopping.\")\n",
    "                return model \n",
    "\n",
    "            progress.set_postfix({\n",
    "                'Loss': f'{avg_loss:.4f}'\n",
    "            })\n",
    "\n",
    "        epoch += 1\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "def eval(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    samples = len(loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader: \n",
    "            \n",
    "            out = model(x).squeeze(1)\n",
    "            loss = loss_fn(out, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / samples\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97abcd-a94d-41ef-bd10-8cdc88c48e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_sent = pd.read_csv('btc_sent.csv')\n",
    "btc_sent.drop(columns=['Accurate Sentiments'], inplace=True)\n",
    "btc_sent['Date'] = pd.to_datetime(btc_sent['Date']).dt.date\n",
    "btc_sent = btc_sent.drop_duplicates(subset=['Date'])\n",
    "start_date = btc_sent['Date'].min()\n",
    "end_date = btc_sent['Date'].max()\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "btc_sent.set_index('Date', inplace=True)\n",
    "btc_sent = btc_sent.reindex(date_range, method=None)\n",
    "btc_sent['Short Description'] = btc_sent['Short Description'].ffill()\n",
    "btc_sent.reset_index(inplace=True)\n",
    "btc_sent.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "print(btc_sent.head(5))\n",
    "print(len(btc_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189cac49-c701-42e7-910b-74dd5a33dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis \n",
    "\n",
    "import lmstudio as lms\n",
    "\n",
    "model = lms.llm(\"gemma-3-12b-it-qat\")\n",
    "sys_prompt = 'Analyze this statement and determine if it is positive, negative, or neutral. Output only 1, 0, or -1'\n",
    "\n",
    "def get_sent(stmt):\n",
    "    result = model.respond(f'{sys_prompt}: {stmt}')\n",
    "    return int(str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557abc7-ff06-4d40-bbbc-5d7e76c14fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "\n",
    "for index, row in btc_sent.iterrows():\n",
    "    date = row['Date']\n",
    "    statement = row['Short Description'] \n",
    "    sentiment = get_sent(statement)\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "    # Just to keep track of progress\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Iteration {index}: {sentiment}\")\n",
    "\n",
    "btc_sent['btc_sentiment'] = sentiments\n",
    "\n",
    "print(btc_sent.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ab1c7-b7f3-4b69-8f7f-041ff715bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = btc_sent['Date'].min()\n",
    "end_date = btc_sent['Date'].max()\n",
    "\n",
    "print(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e9b2f-84bf-4bb3-864f-a84006b12999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert volatility to sentiment when necessary\n",
    "\n",
    "def vtos(volatility, rv, high=0.05, low=0.01):\n",
    "    sign = np.sign(rv)\n",
    "    if volatility >= high:\n",
    "        return 1 * sign\n",
    "    elif volatility < high and volatility > low:\n",
    "        return 0\n",
    "    elif volatility <= low:\n",
    "        return sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8c7f6-f4c8-4cad-9b7b-bfc29a27bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Preprocessed/data.csv')[7:]\n",
    "data.head(1)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "btc_sent['Date'] = pd.to_datetime(btc_sent['Date'])\n",
    "data = pd.merge(data, btc_sent, on='Date', how='outer')\n",
    "\n",
    "def compute_if_nan(row):\n",
    "    if pd.isna(row['btc_sentiment']):\n",
    "        return vtos(row['btc_log_return_volatility'], row['btc_log_return'])\n",
    "    else:\n",
    "        return row['btc_sentiment']\n",
    "\n",
    "data['btc_sentiment'] = data.apply(compute_if_nan, axis=1)\n",
    "\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.drop(columns=['Short Description'])\n",
    "\n",
    "train = data[(data['Date'] >= '2019-03-11') & (data['Date'] <= '2023-12-31')]\n",
    "test = sliced_data = data[(data['Date'] > '2023-12-31')]\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6424a2-c28d-4fdb-98e2-b07c2d14d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_regressors = [\n",
    "    'btc_rolling_mean_return_7', \n",
    "    'btc_prev_log_return_1',  \n",
    "    'btc_prev_log_return_2', \n",
    "    'btc_prev_log_return_3', \n",
    "    'btc_log_return_volatility',\n",
    "    'btc_log_return',\n",
    "    'btc_sentiment',\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "changepoint_range\n",
    "changepoint_prior_scale\n",
    "seasonality_prior_scale\n",
    "\"\"\"\n",
    "changepoints = [0.9, 0.1, 0.1]\n",
    "\n",
    "pmodel = ProphetModel(train, 'btc_close', 'Date', btc_regressors, changepoints) \n",
    "pmodel.add_seasonality(name='quadrennial', period=1461, fourier_order=5)\n",
    "pmodel.fit()\n",
    "\n",
    "ptest = train.rename(columns={'Date': \"ds\", 'btc_close': \"y\"})\n",
    "\n",
    "tt2 = test.rename(columns={'Date': \"ds\", 'btc_close': \"y\"})\n",
    "forecast = pmodel.predict_past(1748, ptest, 'D')\n",
    "print(len(forecast))\n",
    "pmodel.plot(forecast)\n",
    "forecast2 = pmodel.predict(365, tt2, 'D')\n",
    "pmodel.plot(forecast2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf61cff-c278-4d61-85d4-0ecd5cc512b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "merged = pd.merge(ptest, forecast[['ds', 'yhat']], on='ds', how='left')\n",
    "merged = merged.dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged['ds'], merged['y'], label='Log Actual Return', color='blue')\n",
    "plt.plot(merged['ds'], merged['yhat'], label='Predicted Return', color='red', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Return')\n",
    "plt.title('Log-Transformed Actual vs Predicted BTC Returns')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac2497-51cd-4916-8e85-7f63ce956f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(merged['y'], merged['yhat'])\n",
    "mse = mean_squared_error(merged['y'], merged['yhat'])\n",
    "r2 = r2_score(merged['y'], merged['yhat'])\n",
    "\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse}\")\n",
    "print(f\"R² (R-squared): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129ba95-494e-4c1a-8369-d820c20e8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['residual'] = merged['yhat'] - merged['y']\n",
    "merged.rename(columns={'y': 'btc_close'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e10195-1e58-4473-8462-f476bcdf0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = merged[[ \n",
    "                 'yhat',\n",
    "                 'btc_log_return', \n",
    "                 'residual', \n",
    "                 'btc_prev_log_return_1', \n",
    "                 'btc_prev_log_return_2', \n",
    "                 'btc_prev_log_return_3',\n",
    "                 'btc_rolling_mean_return_7',\n",
    "                 'btc_log_return_volatility',\n",
    "                 'btc_sentiment'\n",
    "                ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cde366-1f64-441a-b11c-495f3bf227f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, target_column):\n",
    "        self.features = torch.tensor(df.drop(columns=[target_column]).values, dtype=torch.float32)\n",
    "        self.target = torch.tensor(df[target_column].values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]\n",
    "        \n",
    "dataset = TimeSeriesDataset(result, target_column='residual')\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "network = ResidualNetwork(8, [128, 64, 16]).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "trainm(network, dataloader, optimizer, scheduler, loss_fn, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56c6d6-f390-46a4-b887-21185eab13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(prophet, lstm, dat, span=1):\n",
    "    lstm.eval()\n",
    "    preds = []\n",
    "    vpreds = []\n",
    "    residuals = []\n",
    "    current = dat.iloc[7:8]  # 7th item (index 7)\n",
    "    new_date = current['ds'].values[0]\n",
    "    prev = dat.iloc[0:7]     # items 0 through 6\n",
    "    previmm = dat.iloc[6:7]  # last item of prev\n",
    "    \n",
    "    for _ in range(span):\n",
    "\n",
    "        # Prophet portion\n",
    "        forecast = prophet.predict(1, current, 'D', start=new_date)\n",
    "        yhat = forecast['yhat'].values\n",
    "        vpreds.append(yhat)\n",
    "        residual = yhat - prev.iloc[-1:]['y'].values\n",
    "        log_return = previmm['btc_log_return'].values\n",
    "        btc_close = previmm['y'].values\n",
    "\n",
    "        # MLP Portion\n",
    "        btc_prev_log_return_1 = current['btc_prev_log_return_1'].values\n",
    "        btc_prev_log_return_2 = current['btc_prev_log_return_2'].values\n",
    "        btc_prev_log_return_3 = current['btc_prev_log_return_3'].values\n",
    "        btc_rolling_mean_return_7 = current['btc_rolling_mean_return_7'].values\n",
    "        btc_log_return_volatility = current['btc_log_return_volatility'].values\n",
    "        btc_sentiment = current['btc_sentiment']\n",
    "        \n",
    "        vector = np.stack([\n",
    "            yhat,\n",
    "            log_return,\n",
    "            btc_prev_log_return_1,\n",
    "            btc_prev_log_return_2,\n",
    "            btc_prev_log_return_3,\n",
    "            btc_rolling_mean_return_7,\n",
    "            btc_log_return_volatility,\n",
    "            btc_sentiment\n",
    "        ], axis=1)\n",
    "\n",
    "        tensor = torch.tensor(vector, dtype=torch.float32).to(device)\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "        \n",
    "        pred_residual = lstm(tensor).item()\n",
    "        residuals.append(pred_residual)\n",
    "        \n",
    "\n",
    "        volatility_factor = 1 + (btc_log_return_volatility * 5.0)\n",
    "        pred_price = yhat + pred_residual\n",
    "        preds.append(pred_price)\n",
    "        \n",
    "        last_date = pd.to_datetime(current['ds'].iloc[-1])\n",
    "        new_date = last_date + pd.Timedelta(days=1)\n",
    "\n",
    "        # Because the model is fully autoregressive, we recompute all of these values each iteration\n",
    "        new_row = {\n",
    "            'ds': new_date,\n",
    "            'btc_prev_log_return_1': log_return,\n",
    "            'btc_prev_log_return_2': current['btc_prev_log_return_1'].iloc[-1],\n",
    "            'btc_prev_log_return_3': current['btc_prev_log_return_2'].iloc[-1],\n",
    "            'btc_rolling_mean_return_7': current['btc_rolling_mean_return_7'].iloc[-1],  \n",
    "            'btc_log_return_volatility': current['btc_log_return_volatility'].iloc[-1],  \n",
    "            'btc_log_return': np.log(pred_price / btc_close),\n",
    "            'btc_sentiment': vtos(current['btc_log_return_volatility'].iloc[-1], log_return),\n",
    "        }\n",
    "\n",
    "        current['y'] = pred_price\n",
    "        prev = pd.concat([prev, current])\n",
    "        previmm = prev.iloc[-1:]\n",
    "        current = pd.DataFrame(new_row, index=[0])\n",
    "        current['y'] = 0\n",
    "        last_returns = prev['btc_log_return'].iloc[-7:].tolist()\n",
    "        current['btc_rolling_mean_return_7'] = sum(last_returns) / 7\n",
    "        current['btc_log_return_volatility'] = np.std(last_returns) \n",
    "        \n",
    "    return preds, vpreds, residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442351f-b6ba-4773-aff2-a81a26065d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "regressors = ['Date',\n",
    "              'btc_rolling_mean_return_7', \n",
    "              'btc_prev_log_return_1', \n",
    "              'btc_prev_log_return_2', \n",
    "              'btc_prev_log_return_3',\n",
    "              'btc_log_return_volatility',\n",
    "              'btc_log_return',\n",
    "              'btc_close',\n",
    "              'btc_sentiment'\n",
    "             ]\n",
    "\n",
    "initial = test[regressors]\n",
    "initial = initial.rename(columns={'Date': 'ds', 'btc_close': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bba144-7683-4c0d-a544-82d8c5758ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preds, vpreds, residuals = pre(pmodel, network, initial, span=365)\n",
    "for i in range(10):  \n",
    "    print(f\"Pred: {preds[i]} | VPred: {vpreds[i]} | Residual: {residuals[i]} | Test: {test['btc_close'].iloc[i]}\")\n",
    "\n",
    "test_residuals = test['btc_close'].values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(preds)), np.array(preds), label='Predictions', color='blue')\n",
    "plt.plot(range(len(test_residuals)), test_residuals, label='Actual Price', color='red', linestyle='--')\n",
    "plt.xlabel('Time (Days)')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Prophet Prediction vs Actual Bitcoin Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b22ed-ca1f-4744-b972-ef1ffbfd50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_flat = [item[0] for item in preds]  # Flatten the list of lists\n",
    "vpreds_flat = [item[0] for item in vpreds]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'btc_predictions': preds_flat,\n",
    "    'btc_vpredictions': vpreds_flat,\n",
    "    'btc_residuals': residuals,\n",
    "    'btc_actual': test_residuals[:365]  # Make sure we match the lengths\n",
    "})\n",
    "\n",
    "df.to_csv('btc_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc3766-c27b-4a00-8e84-1a86a17a6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Something funky happened with the lists, so reformat them\n",
    "preds = pd.Series(preds).dropna()\n",
    "test_residuals = pd.Series(test_residuals).dropna()\n",
    "mae = mean_absolute_error(preds, test_residuals)\n",
    "mse = mean_squared_error(preds, test_residuals)\n",
    "r2 = r2_score(preds, test_residuals)\n",
    "mse = mean_squared_error(preds, test_residuals)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R² (R-squared): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63175a13-8f6f-40e9-b1c8-433910d5b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds = preds.rename('btc_predictions')\n",
    "preds = preds.apply(lambda x: x[0] if isinstance(x, (list, np.ndarray)) else x)\n",
    "preds.to_csv('btc_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved as 'predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef453a-9ea4-430c-b13e-ba1a9809f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(pmodel, 'Models/btc_prophet.pkl')\n",
    "torch.save(network, 'Models/btc_mlp.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
