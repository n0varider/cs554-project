{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125b7c4-09af-416f-aee9-f5cf761b1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prophetmodel import ProphetModel\n",
    "from seriesdata import SeriesDataset\n",
    "from residualnn import ResidualNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775aac3-f9af-46d0-89be-6767628eea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure code is running on GPU\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ca544-29ba-43b3-a491-9f46e2150f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "def trainm(model, loader, optimizer, scheduler, loss_fn, epochs):\n",
    "\n",
    "    model.train()\n",
    "    samples = len(loader.dataset)\n",
    "    epoch = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        total_loss = 0.0\n",
    "        progress = tqdm(loader, desc=f'Epoch {epoch+1}/{epochs}', leave=True)\n",
    "        \n",
    "        for i, (x, y) in enumerate(progress):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(x).squeeze(1)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / samples\n",
    "            \n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"NaN loss encountered in epoch {epoch+1}, batch. Stopping.\")\n",
    "                return model \n",
    "\n",
    "            progress.set_postfix({\n",
    "                'Loss': f'{avg_loss:.4f}'\n",
    "            })\n",
    "\n",
    "        epoch += 1\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def eval(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    samples = len(loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader: \n",
    "            \n",
    "            out = model(x).squeeze(1)\n",
    "            loss = loss_fn(out, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / samples\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ea982-fa9e-4cff-b64e-d42475a99d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment extraction\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "macro_sent = pd.read_csv('vix_data.csv')\n",
    "macro_sent['date'] = pd.to_datetime(macro_sent['date']).dt.date\n",
    "macro_sent = macro_sent[(macro_sent['date'] >= pd.to_datetime('2019-03-18').date()) & \n",
    "                        (macro_sent['date'] <= pd.to_datetime('2024-12-31').date())]\n",
    "macro_sent.rename(columns={'date': 'Date', ' value': 'vix'}, inplace=True)\n",
    "\n",
    "start_date = macro_sent['Date'].min()\n",
    "end_date = macro_sent['Date'].max()\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "macro_sent.set_index('Date', inplace=True)\n",
    "macro_sent = macro_sent.reindex(date_range, method=None)\n",
    "macro_sent['vix'] = macro_sent['vix'].ffill()\n",
    "macro_sent.reset_index(inplace=True)\n",
    "macro_sent.rename(columns={'index': 'Date'}, inplace=True)\n",
    "macro_sent['Date'] = pd.to_datetime(macro_sent['Date']).dt.date\n",
    "\n",
    "print(macro_sent.head(5))\n",
    "print(len(macro_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cce442-1b78-496c-a0a0-5d1002f92ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert VIX to sentiment score\n",
    "\n",
    "def vix_tos(vix, rv, high=30, low=15):\n",
    "    sign = np.sign(rv)\n",
    "    if vix >= high:\n",
    "        return -1  \n",
    "    elif vix < high and vix > low:\n",
    "        return 0  \n",
    "    elif vix <= low:\n",
    "        return sign  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8c7f6-f4c8-4cad-9b7b-bfc29a27bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill empty slots in data\n",
    "\n",
    "data = pd.read_csv('Preprocessed/data.csv')[7:]\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "full_date_range = pd.date_range(start=data['Date'].min(), end=data['Date'].max(), freq='D')\n",
    "data = data.set_index('Date').reindex(full_date_range)\n",
    "data = data.ffill()\n",
    "data.reset_index(inplace=True)\n",
    "data.rename(columns={'index': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca528a7-2bfc-430e-9711-2594e2b6dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data with sentiment\n",
    "\n",
    "macro_sent['sp500_log_return'] = np.array(data['sp500_log_return'])\n",
    "sentiments = []\n",
    "newdf = macro_sent.copy()\n",
    "\n",
    "for _, row in macro_sent.iterrows():\n",
    "    sentiment = vix_tos(row['vix'], row['sp500_log_return'])\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "data['macro_sentiment'] = sentiments\n",
    "print(newdf.head())\n",
    "\n",
    "train = data[(data['Date'] >= '2019-03-11') & (data['Date'] <= '2023-12-31')]\n",
    "test = sliced_data = data[(data['Date'] > '2023-12-31')]\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6424a2-c28d-4fdb-98e2-b07c2d14d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_regressors = [\n",
    "    'sp500_rolling_mean_return_7', \n",
    "    'sp500_prev_log_return_1',  \n",
    "    'sp500_prev_log_return_2', \n",
    "    'sp500_prev_log_return_3', \n",
    "    'sp500_log_return_volatility',\n",
    "    'sp500_log_return',\n",
    "    'sp500_close',\n",
    "    'Inflation',            \n",
    "    'bonds_close',          \n",
    "    'macro_sentiment'\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Order of array:\n",
    "changepoint_range\n",
    "changepoint_prior_scale\n",
    "seasonality_prior_scale\n",
    "\"\"\"\n",
    "changepoints = [0.9, 0.1, 0.1]\n",
    "pmodel = ProphetModel(train, 'btc_close', 'Date', sp500_regressors, changepoints)\n",
    "pmodel.add_seasonality(name='quadrennial', period=1461, fourier_order=5)\n",
    "pmodel.fit()\n",
    "\n",
    "ptest = train.rename(columns={'Date': \"ds\", 'btc_close': \"y\"})\n",
    "forecast = pmodel.predict_past(1748, ptest, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf61cff-c278-4d61-85d4-0ecd5cc512b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph predictions on train data\n",
    "\n",
    "merged = pd.merge(ptest, forecast[['ds', 'yhat']], on='ds', how='left')\n",
    "merged = merged.dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged['ds'], merged['y'], label='Log Actual Return', color='blue')\n",
    "plt.plot(merged['ds'], merged['yhat'], label='Predicted Return', color='red', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Return')\n",
    "plt.title('Log-Transformed Actual vs Predicted BTC Returns')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac2497-51cd-4916-8e85-7f63ce956f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MAE, MSE, and R2\n",
    "\n",
    "mae = mean_absolute_error(merged['y'], merged['yhat'])\n",
    "mse = mean_squared_error(merged['y'], merged['yhat'])\n",
    "r2 = r2_score(merged['y'], merged['yhat'])\n",
    "\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse}\")\n",
    "print(f\"R² (R-squared): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129ba95-494e-4c1a-8369-d820c20e8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals\n",
    "\n",
    "merged['residual'] = merged['yhat'] - merged['y']\n",
    "merged.rename(columns={'y': 'btc_close'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e10195-1e58-4473-8462-f476bcdf0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for MLP, set regressors\n",
    "\n",
    "result = merged[[ \n",
    "                 'yhat',\n",
    "                 'sp500_log_return', \n",
    "                 'residual', \n",
    "                 'sp500_prev_log_return_1', \n",
    "                 'sp500_prev_log_return_2', \n",
    "                 'sp500_prev_log_return_3',\n",
    "                 'sp500_rolling_mean_return_7',\n",
    "                 'sp500_log_return_volatility',\n",
    "                 'Inflation',\n",
    "                 'bonds_close',\n",
    "                 'macro_sentiment'\n",
    "                ]]\n",
    "\n",
    "regressors = ['yhat',\n",
    "                 'sp500_log_return',  \n",
    "                 'sp500_prev_log_return_1', \n",
    "                 'sp500_prev_log_return_2', \n",
    "                 'sp500_prev_log_return_3',\n",
    "                 'sp500_rolling_mean_return_7',\n",
    "                 'sp500_log_return_volatility',\n",
    "                 'Inflation',\n",
    "                 'bonds_close',\n",
    "                 'macro_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cde366-1f64-441a-b11c-495f3bf227f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df, in_cols, target_column):\n",
    "        self.features = torch.tensor(df[in_cols].values, dtype=torch.float32)\n",
    "        self.target = torch.tensor(df[target_column].values, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.target[idx]\n",
    "        \n",
    "dataset = TimeSeriesDataset(result, regressors, target_column='residual')\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "network = ResidualNetwork(10, [128, 64, 16]).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "trainm(network, dataloader, optimizer, scheduler, loss_fn, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56c6d6-f390-46a4-b887-21185eab13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoregressive predictor\n",
    "\n",
    "def pre(prophet, mlp, dat, span=2):\n",
    "    mlp.eval()\n",
    "    preds = []\n",
    "    vpreds = []\n",
    "    residuals = []\n",
    "    \n",
    "    for i in range(1, span):\n",
    "\n",
    "        # Prophet portion\n",
    "        current = dat.iloc[i]\n",
    "        new_date = current['ds']\n",
    "        prev = dat.iloc[i-1]\n",
    "        forecast = prophet.predict(1, pd.DataFrame([current]), 'D', start=new_date)\n",
    "        yhat = forecast['yhat']\n",
    "        residual = yhat - prev['y']\n",
    "        residuals.append(residual)\n",
    "        vpreds.append(yhat)\n",
    "\n",
    "\n",
    "        # MLP Portion\n",
    "        vector = np.stack([\n",
    "            yhat[0],\n",
    "            current['sp500_log_return'],\n",
    "            current['sp500_prev_log_return_1'],\n",
    "            current['sp500_prev_log_return_2'],\n",
    "            current['sp500_prev_log_return_3'],\n",
    "            current['sp500_rolling_mean_return_7'],\n",
    "            current['sp500_log_return_volatility'],\n",
    "            current['Inflation'],\n",
    "            current['bonds_close'],\n",
    "            current['macro_sentiment']\n",
    "        ])\n",
    "\n",
    "        vector = torch.tensor(vector, dtype=torch.float32).to(device)\n",
    "        \n",
    "        out = mlp(vector)\n",
    "        out_cpu = out.cpu().detach().numpy()\n",
    "\n",
    "        price = yhat - out_cpu\n",
    "        preds.append(price)\n",
    "        \n",
    "    return preds, vpreds, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f88aa-957a-4d3d-b182-f7c458c1d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test[['Date', 'btc_close'] + sp500_regressors]\n",
    "prophet_subset = test_set.rename(columns={'Date': 'ds', 'btc_close': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12931d64-604c-4d5c-a416-a22935c4f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph predictions\n",
    "# preds = Overall prediction (Prophet -> MLP -> out)\n",
    "# vpreds = Prophet raw predictions\n",
    "# residuals = Predicted residual value\n",
    "\n",
    "preds, vpreds, residuals = pre(pmodel, network, prophet_subset, span=365)\n",
    "for i in range(10): \n",
    "    print(f\"Pred: {preds[i][0]} | VPred: {vpreds[i][0]} | Residual: {residuals[i][0]} | Test: {test['btc_close'].iloc[i]}\")\n",
    "\n",
    "test_residuals = test['btc_close'].iloc[:364].values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(preds)), np.array(preds), label='Predictions', color='blue')\n",
    "plt.plot(range(len(test_residuals)), test_residuals, label='Actual Price', color='red', linestyle='--')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Predicted vs Actual BTC Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1b166-abbe-4b67-aca4-cd92f7635381",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_flat = [item[0] for item in preds]  # Flatten the list of lists\n",
    "vpreds_flat = [item[0] for item in vpreds]\n",
    "residuals_flat = [item[0] for item in residuals]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'macro_predictions': preds_flat,\n",
    "    'macro_vpredictions': vpreds_flat,\n",
    "    'macro_residuals': residuals_flat,\n",
    "    'macro_actual': test_residuals[:365]  # Make sure we match the lengths\n",
    "})\n",
    "\n",
    "df.head()\n",
    "df.to_csv('macro_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51957b0-bf5e-47c5-8669-e4a0031e0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(preds, test_residuals)\n",
    "mse = mean_squared_error(preds, test_residuals)\n",
    "r2 = r2_score(preds, test_residuals)\n",
    "\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n",
    "print(f\"MSE (Mean Squared Error): {mse}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {np.sqrt(mse)}\")\n",
    "print(f\"R² (R-squared): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3d522-ef62-44bc-a8d9-96bc7c1c2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'macro_predictions': [pred.iloc[0] for pred in preds]})\n",
    "df.to_csv('macro_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved as 'macro_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb581c-6d30-4678-95b9-785f236adb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(pmodel, 'Models/macro_prophet.pkl')\n",
    "torch.save(network, 'Models/macro_mlp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649658e7-7749-435a-b62f-d35dc5a2310d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
